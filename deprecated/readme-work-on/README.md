Welcome to STA 360, Fall 2020! 

The readings/preparations for the class can be found at the very bottom of this file for reference. These are subject to change and will be updated as the course progresses. 

## Tenative Course Schedule 

TODO: check dates and make these consistent with duke's new schedule. 

(Please note that this is subject to change given that we still do not have a class time, location for Fall 2020 yet, but I will update this often leading up to the first day of class to try and make this a smooth semester for all. I appreciate everyone's patience as we all go through this together. Importantly, know that I care very much your learning and appreciate your feedback! I look forward to having you in class very much, and hope that we're all in person like we were before as soon as possible! 

<pre><b> Week 1: Tuesday, August 18 - Thursday, August 20, Intro to Course </pre>
 
Module 0: Introduction to Course Expectations and Overview of Bayesian Statistics

Module 1: Intro to Bayesian Statistics 

Lecture 1: Tuesday, August 18: Intro to Course, Expectations, and Bayesian Statistics
- [Introduction to Bayesian Statistics and Course Expectations](https://github.com/resteorts/modern-bayes/blob/master/lecturesModernBayes20/lecture-0/00-intro-to-Bayes.pdf)
- [Introduction to Bayesian Statistics](https://github.com/resteorts/modern-bayes/blob/master/lecturesModernBayes20/lecture-1/01-intro-to-Bayes.pdf) 

Lecture 2: Thursday, August 20: Introduction to Bayesian Statistics (Continued) 
- [Introduction to Bayesian Statistics](https://github.com/resteorts/modern-bayes/blob/master/lecturesModernBayes20/lecture-1/01-intro-to-Bayes.pdf)

Labs: 
- Lab 1: [Review of R](https://github.com/resteorts/modern-bayes/blob/master/labs/01-intro-r/lab-01.pdf)
- [Video Review of R](https://github.com/resteorts/modern-bayes/blob/master/labs/01-intro-r/video-lab-01.mp4)
- [Lab 1 Solution](https://github.com/resteorts/modern-bayes/blob/master/labs/01-intro-r/lab-01-solution.pdf)

Reading (complete before August 18, 2020): 

- [History of Bayes and Introduction to Bayesian Statistics](https://github.com/resteorts/modern-bayes-virtual/blob/master/lecturesModernBayes20/lecture-1/01-history-of-Bayes.pdf)
- Read Ch 1, Ch 2.1 -- 2.6. (Hoff), Read Ch 1.1 (http://www2.stat.duke.edu/~rcs46/books/bayes_manuscripts.pdf)
- Read Ch 3 (Hoff) 
- Read Ch 2.5--2.7 (http://www2.stat.duke.edu/~rcs46/books/bayes_manuscripts.pdf)
- Read Ch 4 for predictive inference (Hoff). 
- Read Ch 2.9 (Posterior predictive inference) (http://www2.stat.duke.edu/~rcs46/books/bayes_manuscripts.pdf). 

<pre><b> Week 2: Tuesday, September 1 - Thursday, September 3, Intro to Bayes and Decision Theory </pre>

Module 1: Intro to Bayesian Statistics (Continued)

Module 2:  Introduction to Decision Theory 

Lecture 3: Tuesday September 1: Introduction to Bayesian Statistics (Continued) 
- [Introduction to Bayesian Statistics](https://github.com/resteorts/modern-bayes/blob/master/lecturesModernBayes20/lecture-1/01-intro-to-Bayes.pdf) 

Lecture 4: Thursday September 3: Introduction to Decision Theory 
- [Introduction to Decision Theory](https://github.com/resteorts/modern-bayes/blob/master/lecturesModernBayes20/lecture-2/02-intro-to-Bayes.pdf)

Labs: 
- Lab 2: [Introduction to Bayes](https://github.com/resteorts/modern-bayes/blob/master/labs/02-intro-to-bayes/lab-02.pdf)
- [Labs 2 Videos](https://github.com/resteorts/modern-bayes/tree/master/labs/02-intro-to-bayes/videos)

Reading:  Read Ch 2.1 -- 2.4 (http://www2.stat.duke.edu/~rcs46/books/bayes_manuscripts.pdf) 
This is not covered in Hoff. (Complete before Tuesday Sept 1). 


<pre><b> Week 3: Tuesday, September 8 - Thursday, September 10, Intro to Decision Theory and Advanced Conjugacy </pre>
- Lecture 5: Tuesday September 8: Module 2:  Introduction to Decision Theory (Continued)
- [Introduction to Decision Theory](https://github.com/resteorts/modern-bayes/blob/master/lecturesModernBayes20/lecture-2/02-intro-to-Bayes.pdf)
- Lecture 6: Thursday September 10: Module 3: Advanced Conjucacy (Normal-Normal)
- [Introduction to Normal Conjugacy](https://github.com/resteorts/modern-bayes/blob/master/lecturesModernBayes20/lecture-3/03-normal-distribution.pdf) 
- Lab 3: Introduction to Decision Theory

<pre><b> Week 4: Tuesday, September 15 - Thursday, September 17, Advanced Conjuacy </pre>
- Lecture 7: Tuesday September 15: Module 3:  Advanced Conjucacy (Normal-Normal)
- [Introduction to Normal Conjugacy](https://github.com/resteorts/modern-bayes/blob/master/lecturesModernBayes20/lecture-3/03-normal-distribution.pdf) 
- Lecture 8: Thursday September 17: Module 4: Advanced Conjucacy (Normal-Gamma) 
- [Introduction to Normal-Gamma Conjugacy](https://github.com/resteorts/modern-bayes/blob/master/lecturesModernBayes20/lecture-4/04-normal-gamma.pdf)
- Lab 4: Introduction to Gaussian Conjugate Models 

Reading:  Ch 2, Example 2.7 and 2.8 (in terms of variance derivations), (http://www2.stat.duke.edu/~rcs46/books/bayes_manuscripts.pdf). This covers the Normal-normal conjugate model.
Reading: Ch 2, Example 2.13, (http://www2.stat.duke.edu/~rcs46/books/bayes_manuscripts.pdf) This covers the Normal-Gamma conjugate model. 

<pre><b> Week 5: Tuesday, September 22 - Thursday, September 24, Advanced Conjuacy and Intro to Monte Carlo </pre>
- Lecture 9: Tuesday September 22: Module 4:  Advanced Conjucacy (Normal-Gamma) (Continued
- [Introduction to Normal-Gamma Conjugacy](https://github.com/resteorts/modern-bayes/blob/master/lecturesModernBayes20/lecture-4/04-normal-gamma.pdf)
- Lecture 10: Thursday September 24: Module 5: Introduction to Monte Carlo 
- [Intro to Monte Carlo](https://github.com/resteorts/modern-bayes/blob/master/lecturesModernBayes20/lecture-5/05-monte-carlo.pdf)
- Lab 4: Introduction to Gaussian Conjugate Models 

<pre><b> Exam I: To be announced, Material: Modules 1 -- 3. </pre>

- Information about Exam I: To be placed here. 

<pre><b> Week 6: Tuesday, September 29 - Thursday, October 1, Intro to Monte Carlo and Metropolis </pre>
- Lecture 11: Tuesday September 29: Module 5:  Introduction to Monte Carlo  (Continued)
- [Intro to Monte Carlo](https://github.com/resteorts/modern-bayes/blob/master/lecturesModernBayes20/lecture-5/05-monte-carlo.pdf)
- Lecture 12: Thursday October 1: Module 6:  The Metropolis Algorithm 
- [Intro to Metropolis](https://github.com/resteorts/modern-bayes/blob/master/lecturesModernBayes20/lecture-6/06-metropolis.pdf)
- Lab 5: Introduction to Gaussian Conjugate Models 

Reading: 
Module 5 (Introduction to Monte Carlo):
Read Hoff, Chapter 4. 
Read PhD notes, Chapter 5.1, 5.3
Remark: The slides will cover examples not always in Hoff or the notes. 

Reading: Ch 2, Example 2.13, (http://www2.stat.duke.edu/~rcs46/books/bayes_manuscripts.pdf)
 
 <pre><b>  Week 7: Tuesday, October 6 - Thursday, October 8, Intro to Metropolis and Gibbs </pre>
 - Lecture 13: Tuesday October 6: Module 6:  The Metropolis Algorithm (Continued)
- [Intro to Metropolis](https://github.com/resteorts/modern-bayes/blob/master/lecturesModernBayes20/lecture-6/06-metropolis.pdf)
 - Lab 7: The Metropolis Algorithm
 - Lecture 14: Thursday October 8: Module 7:  Introduction to Gibbs Sampling 
 - [Intro to Gibbs](https://github.com/resteorts/modern-bayes/blob/master/lecturesModernBayes20/lecture-7/07-gibbs-part1.pdf)

Reading:  Modules 6--7 (One Stage Gibbs Sampling and the Metropolis Algorithm)
Read Hoff, Ch 6
Read Phd notes, Chapter 5.2
Remark: The slides will cover examples not always in Hoff or the notes.  
For Metropolis Algorithm, read Hoff 10.2 


 <pre><b> Week 8: Tuesday, October 20 - Thursday, October 22 </pre>
- Lecture 15: Tuesday October 20: Module 7:  Intro to Gibbs (Continued)
- [Intro to Gibbs](https://github.com/resteorts/modern-bayes-virtual/blob/master/lecturesModernBayes20/lecture-7/07-gibbs-part1.pdf)
- Lab 8: XXX
- Lecture 16: Thursday October 22: Module 7:  Multi-stage Gibbs sampling and Missing Data
- [Multistage Gibbs](https://github.com/resteorts/modern-bayes-virtual/blob/master/lecturesModernBayes20/lecture-7/07-gibbs-part2-multi-stage.pdf)

 <pre><b> Week 9: Tuesday, October 27 - Thursday, October 29 </pre>
- Lecture 17: Tuesday October 27: Module 7:  Data Augmentation 
- [Data Augmentataion](https://github.com/resteorts/modern-bayes-virtual/blob/master/lecturesModernBayes20/lecture-7/07-gibbs-part3-data-augment.pdf)
- Lab 9: XXXX
- Lecture 18: Thursday October 29: Module 7: Data Augmentation and Mixture Models 
- [Data Augmentation and Mixture Models](https://github.com/resteorts/modern-bayes-virtual/blob/master/lecturesModernBayes20/lecture-7/07-gibbs-part4-data-augment.pdf)

Reading: Module 7  (Multistage Gibbs and Latent Variable Allocation)
The material in class is not in the PhD notes for the most part. 
(Note: I will not be following the book with regards to the examples in Hoff
but I do recommend reading them).  Gibbs reading: You should have already read Ch 6, so review as need be. 
Metropolis Hastings: 10.4 and 10.5, Latent variable allocation: Chapter 12

<pre><b> Exam II: To be announced, Material: Modules 4 -- 7. </pre>

- Information about Exam II: To be placed here. 

<pre><b> Week 10: Tuesday, November 3 - 5 Thursday, November 12 </pre>
- Lecture 19: Tuesday November 10: Module 8:  Multivariate Normal Distribution
- [Multivariate Normal](https://github.com/resteorts/modern-bayes/blob/master/lecturesModernBayes20/lecture-8/08-multivariate-norm.pdf)
- Lab 10: Multivariate Normal
- Lecture 20: Thursday November 12: Module 8: Data Augmentation and Mixture Models 
- [Multivariate Normal and Missing Data](https://github.com/resteorts/modern-bayes/blob/master/lecturesModernBayes20/lecture-8/08-missing-data.pdf)

Readings: Module 9 (Multivariate Normal Distribution)
Hoff: Chapter 7.1--7.4

<pre><b> Week 10: Tuesday, November 10 - Thursday, November 12 </pre>
- Lecture 21: Tuesday November 10: Module 9:  Linear Regression 
- [Linear Regression](https://github.com/resteorts/modern-bayes/blob/master/lecturesModernBayes20/lecture-9/9-linear-regression.pdf)
- Lab 9: Model Selection 
- Lecture 22: Module 10: Model Selection
- [Model Selection](https://github.com/resteorts/modern-bayes/blob/master/lecturesModernBayes20/lecture-10/10-model-selection.pdf)

Readings: Module 11 (Linear Regression)
Hoff: Chapter 9.1--9.2
[Probit Regression](https://github.com/resteorts/modern-bayes/blob/master/lecturesModernBayes20/lecture-9/9-probit-regression.pdf)

<pre><b> Week 11: Tuesday, November 16 - Thursday, November 18 </pre>
- Review and Final Exam 


# Suggested Readings

## Hoff

I suggest that you read all of Hoff and you will be expected to have read the readings that correspond with the notes before 
coming to class. There are also notes that I have written under readings/ that you may find helping as additional resources. 

## Required Material

Before starting the course for the fall semester, I would highly recommend review the pre-req material for the course on the [syllabus](https://github.com/resteorts/modern-bayes/blob/master/syllabus/syllabus-sta360-fall20.pdf). Given the shortened semester, please make sure that you are 100 percent comfortable with the pre-req material before taking STA 360. If you have any questions regarding this, please reach out to me as soon as possible. 

## Introduction/Review to R

- [Intro to R, Part I](https://github.com/resteorts/modern-bayes/blob/master/lecturesModernBayes20/background-intro-to-R/introToR-partI.pdf)
- [Intro to R, Part II](https://github.com/resteorts/modern-bayes/blob/master/lecturesModernBayes20/background-intro-to-R/introToR-partII.pdf)
- [Intro to R, Part III](https://github.com/resteorts/modern-bayes/blob/master/lecturesModernBayes20/background-intro-to-R/introToR-partIII.pdf)
- [Intro to R, Part IV](https://github.com/resteorts/modern-bayes/blob/master/lecturesModernBayes20/background-intro-to-R/introToR-partIV.pdf)
- [Intro to R, Part V](https://github.com/resteorts/modern-bayes/blob/master/lecturesModernBayes20/background-intro-to-R/introToR-partV.pdf)
- [Intro to R, Videos](https://github.com/resteorts/modern-bayes/tree/master/lecturesModernBayes20/background-intro-to-R/videos)
- Reference Text: http://shop.oreilly.com/product/9780596809164.do (The R Cookbook, not to be confused with the one for graphics). 

## github

Please learn github if you're not already familiar as this is where the course resources are located. https://lab.github.com/). Homework releases and submissions will be done on Sakai. 


## Other

If Sakai is problematic for you due to your location, please let me know in advance, so I can think of alternative options, such as uploads via github. If you are having internet issues, please let me know as well. 


## Other readings :

- Credible Intervals): Cred intervals are covered on pages 52 and 267 of Hoff. 
- Read Ch 4.1--4.1 (Cred intervals) (http://www2.stat.duke.edu/~rcs46/books/bayes_manuscripts.pdf)
- Here is a brief intro from PSU on Multinomial sampling for a review: 
https://onlinecourses.science.psu.edu/stat504/node/59


